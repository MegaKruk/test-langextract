# Databricks notebook source
# MAGIC %md
# MAGIC # PDFConverter Testing Notebook
# MAGIC
# MAGIC This notebook tests the PDFConverter class with files from SampleDOCTYPES.csv
# MAGIC
# MAGIC **Test Scope:**
# MAGIC - Verify PDFConverter can import and initialize
# MAGIC - Test file type detection and filtering
# MAGIC - Convert sample files to PDF
# MAGIC - Analyze conversion success rates
# MAGIC - Validate output PDFs

# COMMAND ----------

# MAGIC %md
# MAGIC ## Setup and Imports

# COMMAND ----------

import sys
import os

# For some reason I have to do this terribleness for imports below to work
notebook_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()
project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

config_path = os.path.join(project_root, 'config', 'main_config.cfg')

print(f"project_root: {project_root}")
print(f"notebook_dir: {notebook_dir}")
print(f"config_path: {config_path}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Import PDFConverter

# COMMAND ----------

from processes.docu_intelli.pdf_converter import PDFConverter
from utils.config import get_main_config
import pandas as pd
import tempfile
from pathlib import Path

print("‚úì PDFConverter imported successfully")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Initialize PDFConverter

# COMMAND ----------

# Create output directory in temp
output_dir = tempfile.mkdtemp(prefix='pdf_converter_test_')
print(f"Output directory: {output_dir}")

# Initialize converter
pdfc = PDFConverter(output_dir=output_dir)
print("\n‚úì PDFConverter initialized successfully")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Load Sample Files from CSV

# COMMAND ----------

# Load the CSV with sample document names
csv_path = "/Volumes/xla_claimseverity_prd_spl/store/unstructured/data_intake/Data_For_Testing/PDR_Converter/SampleDOCTYPES.csv"
df = pd.read_csv(csv_path)

# Base directory to search
base_dir = "/Volumes/xla_claimseverity_prd_spl/store/unstructured/data_intake/"

def find_file(filename, search_dir):
    """Recursively search for a file in a directory tree."""
    for root, dirs, files in os.walk(search_dir):
        if filename in files:
            return os.path.join(root, filename)
    return None

# Find full path for each file
df['Found_Path'] = df['Documents'].apply(lambda x: find_file(x, base_dir))

print(f"Total files in CSV: {len(df)}")
print(f"Files found: {df['Found_Path'].notna().sum()}")
display(df.head(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## Verify All Files Were Found

# COMMAND ----------

# Check if we found path for every single file from original csv or is any missing
missing_files = df[df['Found_Path'].isnull()]
if missing_files.empty:
    print("‚úì All files from the original CSV were found.")
else:
    print("‚ö† Missing files from the original CSV:")
    display(missing_files[['Documents', 'Type']])

# COMMAND ----------

# MAGIC %md
# MAGIC ## Analyze File Extensions in Sample Set

# COMMAND ----------

# List all unique file types that we found along with count of occurrences based on actual file extension
print("Unique file extensions found in the sample set and their counts:")
df['Extension'] = df['Found_Path'].apply(lambda x: os.path.splitext(x)[1].lower() if pd.notna(x) else None)
ext_counts = df['Extension'].value_counts().reset_index()
ext_counts.columns = ['Extension', 'Count']
display(ext_counts)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Test File Support Detection

# COMMAND ----------

print("=" * 80)
print("TESTING FILE SUPPORT DETECTION")
print("=" * 80)

# Add support status to dataframe
def check_support(file_path):
    if pd.isna(file_path):
        return False, "N/A", "File not found"
    is_supported, reason = pdfc.is_supported_file(file_path)
    ext = os.path.splitext(file_path)[1].lower().lstrip('.')
    return is_supported, ext, reason

df[['Is_Supported', 'Ext', 'Support_Reason']] = df['Found_Path'].apply(
    lambda x: pd.Series(check_support(x))
)

# Summary statistics
print(f"\nüìä SUPPORT SUMMARY:")
print(f"Total files: {len(df)}")
print(f"Supported files (will be converted): {df['Is_Supported'].sum()}")
print(f"Unsupported/Skipped files: {(~df['Is_Supported']).sum()}")

# Group by support reason
print("\nüìã BREAKDOWN BY REASON:")
reason_counts = df.groupby('Support_Reason').size().sort_values(ascending=False)
for reason, count in reason_counts.items():
    print(f"  {reason}: {count} files")

# Show examples of each category
print("\n" + "=" * 80)
print("EXAMPLES BY CATEGORY")
print("=" * 80)

categories = df['Support_Reason'].unique()
for category in categories:
    print(f"\n{category}:")
    examples = df[df['Support_Reason'] == category].head(3)
    for _, row in examples.iterrows():
        print(f"  - {row['Documents']} ({row['Ext']})")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Detailed Extension Analysis

# COMMAND ----------

# Analyze supported vs unsupported extensions
supported_exts = df[df['Is_Supported']]['Ext'].value_counts()
unsupported_exts = df[~df['Is_Supported']]['Ext'].value_counts()

print("üìä SUPPORTED EXTENSIONS (will be converted):")
print(supported_exts)

print("\n‚ùå UNSUPPORTED/SKIPPED EXTENSIONS:")
print(unsupported_exts)

# Create visualization-friendly dataframe
ext_summary = pd.DataFrame({
    'Extension': list(set(supported_exts.index) | set(unsupported_exts.index)),
})
ext_summary['Supported_Count'] = ext_summary['Extension'].map(supported_exts).fillna(0).astype(int)
ext_summary['Unsupported_Count'] = ext_summary['Extension'].map(unsupported_exts).fillna(0).astype(int)
ext_summary['Total'] = ext_summary['Supported_Count'] + ext_summary['Unsupported_Count']
ext_summary = ext_summary.sort_values('Total', ascending=False)

display(ext_summary)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Convert Supported Files to PDF

# COMMAND ----------

print("=" * 80)
print("STARTING PDF CONVERSION")
print("=" * 80)

# Get list of supported files
supported_files = df[df['Is_Supported']]['Found_Path'].tolist()

print(f"\nüìÑ Converting {len(supported_files)} supported files...")
print(f"Output directory: {output_dir}\n")

# Perform batch conversion
conversion_results = pdfc.batch_convert(supported_files, verbose=True)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Analyze Conversion Results

# COMMAND ----------

print("=" * 80)
print("CONVERSION RESULTS ANALYSIS")
print("=" * 80)

# Create results dataframe
results_data = []
for file_path, success, output_path, message in conversion_results['results']:
    results_data.append({
        'Filename': os.path.basename(file_path),
        'Extension': os.path.splitext(file_path)[1].lower().lstrip('.'),
        'Success': success,
        'Output_Path': output_path,
        'Message': message
    })

results_df = pd.DataFrame(results_data)

# Overall statistics
print(f"\nüìä OVERALL STATISTICS:")
print(f"Total files processed: {conversion_results['total']}")
print(f"‚úì Successful conversions: {conversion_results['successful']}")
print(f"‚úó Failed conversions: {conversion_results['failed']}")
print(f"‚äò Skipped files: {conversion_results['skipped']}")

if conversion_results['total'] > 0:
    success_rate = (conversion_results['successful'] / conversion_results['total']) * 100
    print(f"Success rate: {success_rate:.1f}%")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Conversion Success by File Type

# COMMAND ----------

print("\nüìã SUCCESS RATE BY FILE TYPE:")
print("=" * 80)

success_by_type = results_df[results_df['Success']].groupby('Extension').size()
total_by_type = results_df.groupby('Extension').size()
failed_by_type = results_df[~results_df['Success']].groupby('Extension').size()

type_summary = pd.DataFrame({
    'Extension': total_by_type.index,
    'Total': total_by_type.values,
    'Successful': [success_by_type.get(ext, 0) for ext in total_by_type.index],
    'Failed': [failed_by_type.get(ext, 0) for ext in total_by_type.index]
})
type_summary['Success_Rate_%'] = (type_summary['Successful'] / type_summary['Total'] * 100).round(1)
type_summary = type_summary.sort_values('Total', ascending=False)

display(type_summary)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Show Failed Conversions (if any)

# COMMAND ----------

failed_conversions = results_df[~results_df['Success'] & (results_df['Message'] != 'File is already a PDF')]

if len(failed_conversions) > 0:
    print(f"‚ö† {len(failed_conversions)} FAILED CONVERSIONS:")
    print("=" * 80)
    display(failed_conversions[['Filename', 'Extension', 'Message']])
else:
    print("‚úì No failed conversions! All supported files were successfully converted.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Verify Output PDFs

# COMMAND ----------

print("=" * 80)
print("VERIFYING OUTPUT PDFS")
print("=" * 80)

# Get statistics from converter
stats = pdfc.get_conversion_stats()

print(f"\nüìÅ Output Directory: {stats['output_directory']}")
print(f"üìÑ Total PDFs created: {stats['total_pdfs']}")
print(f"üíæ Total size: {stats['total_size_mb']:.2f} MB")

if stats['total_pdfs'] > 0:
    avg_size = stats['total_size_mb'] / stats['total_pdfs']
    print(f"üìè Average PDF size: {avg_size:.2f} MB")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Sample Output Files

# COMMAND ----------

print("\nüìù SAMPLE OUTPUT FILES (first 10):")
print("=" * 80)

successful_outputs = results_df[results_df['Success']].head(10)
for idx, row in successful_outputs.iterrows():
    file_size = os.path.getsize(row['Output_Path']) / 1024  # KB
    print(f"{row['Filename']} ({row['Extension']}) ‚Üí {os.path.basename(row['Output_Path'])} ({file_size:.1f} KB)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Test Document Types vs Sample Types

# COMMAND ----------

print("=" * 80)
print("COMPARING SAMPLE SET VS ALL DOCUMENT TYPES")
print("=" * 80)

# List all unique file types that are total in the Document_Types folder and subfolders
doc_types_dir = "/Volumes/xla_claimseverity_prd_spl/store/unstructured/data_intake/Document_Types/"
all_extensions = []

for root, dirs, files in os.walk(doc_types_dir):
    for file in files:
        ext = os.path.splitext(file)[1].lower()
        if ext:
            all_extensions.append(ext)

from collections import Counter
ext_counts_all = Counter(all_extensions)

print("\nüìä All unique file extensions in Document_Types and their counts:")
all_ext_counts = pd.DataFrame(
    list(ext_counts_all.items()), 
    columns=['Extension', 'Count']
).sort_values('Count', ascending=False)

display(all_ext_counts)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Extensions Not in Sample Set

# COMMAND ----------

# Extensions in all_ext_counts but not in sample set
sample_exts = set(df['Extension'].dropna().unique())
diffs_in_samples = all_ext_counts[~all_ext_counts['Extension'].isin(sample_exts)]

print("\nüîç EXTENSIONS IN DOCUMENT_TYPES BUT NOT IN SAMPLE SET:")
print("=" * 80)

if len(diffs_in_samples) > 0:
    display(diffs_in_samples)
    
    # Categorize these extensions
    diffs_list = diffs_in_samples['Extension'].str.lstrip('.').tolist()
    supported_not_in_sample = [ext for ext in diffs_list if ext in pdfc.SUPPORTED_EXTENSIONS]
    unsupported_not_in_sample = [ext for ext in diffs_list if ext not in pdfc.SUPPORTED_EXTENSIONS and ext != 'pdf']
    
    print(f"\n‚úì Supported by converter but not in sample: {supported_not_in_sample}")
    print(f"‚úó Unsupported by converter: {unsupported_not_in_sample}")
else:
    print("All extensions in Document_Types are represented in the sample set.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Test Summary Report

# COMMAND ----------

print("=" * 80)
print("FINAL TEST SUMMARY REPORT")
print("=" * 80)

print(f"\nüìã TEST DATASET:")
print(f"  Total files in CSV: {len(df)}")
print(f"  Files found on disk: {df['Found_Path'].notna().sum()}")
print(f"  Unique extensions: {df['Extension'].nunique()}")

print(f"\nüéØ SUPPORT ANALYSIS:")
print(f"  Supported for conversion: {df['Is_Supported'].sum()}")
print(f"  Already PDF (skipped): {(df['Support_Reason'] == 'File is already a PDF').sum()}")
print(f"  Unsupported extension: {(df['Support_Reason'].str.contains('Unsupported', na=False)).sum()}")

print(f"\n‚úÖ CONVERSION RESULTS:")
print(f"  Successful conversions: {conversion_results['successful']}")
print(f"  Failed conversions: {conversion_results['failed']}")
print(f"  Success rate: {(conversion_results['successful'] / max(len(supported_files), 1) * 100):.1f}%")

print(f"\nüìÅ OUTPUT:")
print(f"  Output directory: {output_dir}")
print(f"  PDFs created: {stats['total_pdfs']}")
print(f"  Total size: {stats['total_size_mb']:.2f} MB")

print(f"\nüîß CONVERTER CAPABILITIES:")
print(f"  Supported extensions: {sorted(pdfc.SUPPORTED_EXTENSIONS)}")
print(f"  Documents: {sorted(pdfc.DOCUMENT_EXTENSIONS)}")
print(f"  Spreadsheets: {sorted(pdfc.SPREADSHEET_EXTENSIONS)}")
print(f"  Images: {sorted(pdfc.IMAGE_EXTENSIONS)}")

print("\n" + "=" * 80)
print("‚úì TESTING COMPLETE")
print("=" * 80)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Cleanup (Optional)

# COMMAND ----------

# Uncomment to clean up output directory
# import shutil
# shutil.rmtree(output_dir)
# print(f"‚úì Cleaned up output directory: {output_dir}")
